{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e8647ca",
   "metadata": {},
   "source": [
    "IMPORT modules(This part is dataAnalysis.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3232ae28",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c0918",
   "metadata": {},
   "source": [
    "DATA EXTRACTION, ANALYSIS AND SIMPLIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0acc676",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"previous_loan_defaults_on_file\",\n",
    "    \"person_gemder\"\n",
    "]\n",
    "data = pd.read_csv(\"loan_data.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data.drop(columns=[\"loan_int_rate\",\"person_gender\"],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "data.replace({\n",
    "    \"Yes\" : 1,\n",
    "    \"No\" : 0,\n",
    "    \"male\" : 1,\n",
    "    \"female\" : 0\n",
    "},inplace=True)\n",
    "\n",
    "# print(chi2(data[features],data['loan_status'])) \n",
    "\n",
    "output for previous_loan_defaults_on_file : (array([6530.85714286]), array([0.]))\n",
    "Strong relation\n",
    "\n",
    "output for person_gender : (array([0.00635183]), array([0.93647718]))\n",
    "No significant relation\n",
    "\n",
    "'''\n",
    "# output shows a very strong and significant relationship\n",
    "\n",
    "\n",
    "# print(data['previous_loan_defaults_on_file'].value_counts())\n",
    "\n",
    "# Simplified (basically)\n",
    "# data.to_csv(\"loan_dataS.csv\",index=False)\n",
    "\n",
    "\n",
    "''' \n",
    "    The point biseral coefficient is a method(score) used to determine\n",
    "    correltaion between a continuous feture and a categorical(binary) feature\n",
    "'''\n",
    "def pointBiseralCoeff(x0,x1):\n",
    "    m0 = x0.mean()\n",
    "    m1 = x1.mean()\n",
    "    s = np.concatenate([x0,x1]).std()\n",
    "    n0 = len(x0)\n",
    "    n1 = len(x1)\n",
    "    n = n0 + n1\n",
    "\n",
    "    return (((m1 - m0 )/s) * np.sqrt(n0*n1/(n**2)))\n",
    "\n",
    "\n",
    "data0 = data[data['loan_status']==0]\n",
    "data1 = data[data['loan_status']==1]\n",
    "\n",
    "X0 = data0[\"cb_person_cred_hist_length\"]\n",
    "X1 = data1[\"cb_person_cred_hist_length\"]\n",
    "print(pointBiseralCoeff(X0,X1)) \n",
    "\n",
    "\n",
    "'''\n",
    "# X0 = data0['loan_percent_income']\n",
    "# X0 = data0['credit_score']\n",
    "# X0 = data0[\"person_income\"]\n",
    "X0 = data0[\"person_emp_exp\"]\n",
    "X0 = data0[\"cb_person_cred_hist_length\"]\n",
    "X0 = data0[\"loan_amnt\"]\n",
    "\n",
    "# X1 = data1['loan_percent_income']\n",
    "# X1 = data1['credit_score']\n",
    "# X1 = data1[\"person_income\"]\n",
    "X1 = data1[\"person_emp_exp\"]\n",
    "X1 = data1[\"cb_person_cred_hist_length\"]\n",
    "X1 = data1[\"loan_amnt\"]\n",
    "\n",
    "\n",
    "print(pointBiseralCoeff(X0,X1)) \n",
    "\n",
    "output : 0.3848803799720417 for \"loan_percent_income\"-> Shows a MODERATELY STRONG RELATIONSHIP\n",
    "output : -0.007647176334884879 for \"credit_score\"\n",
    "output : -0.13580771683574247 for \"person_income\"-> Shows a WEAK NEGATIVE RELATIONSHIP\n",
    "output : -0.02048125886337787 for \"person_emp_exp\"-> Shows a VERY WEAK NEGATIVE RELATIONSHIP\n",
    "output : -0.014850683660985917 for \"cb_person_cred_hist_length\"-> Shows a VERY WEAK RELATIONSHIP\n",
    "output : 0.10771446698132857 for \"loan_amnt\"-> Shows a  WEAK RELATIONSHIP\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098e4436",
   "metadata": {},
   "source": [
    "MOdel TRAINING AND TESTING ( Content below This was kept in modelTraining.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab70741",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "data = pd.read_csv(\"loan_dataS.csv\")\n",
    "# data = pd.read_csv(\"loan_dataUnderSmapled.csv\")\n",
    "X = data[data.columns[:-1]].to_numpy()\n",
    "y = data[data.columns[-1]].to_numpy()\n",
    "\n",
    "# features = [\n",
    "#     'person_education',\n",
    "#     'person_home_ownership',\n",
    "#     'loan_intent',\n",
    "#     'previous_loan_defaults_on_file'    \n",
    "# ]\n",
    "\n",
    "cc= [1,4,6,10]\n",
    "ff = [0,2,3,5,7,8,9]\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "for col in cc:\n",
    "    X[col] = X[col].astype('category')\n",
    "for col in ff:\n",
    "    X[col] = X[col].astype('float')\n",
    "\n",
    "\n",
    "xTrain,xTest,yTrain,yTest = train_test_split(\n",
    "                                                X, \n",
    "                                                 y, \n",
    "                                                 test_size=0.22,\n",
    "                                                random_state=42,\n",
    "                                                stratify=y\n",
    "                                            )\n",
    "\n",
    "# print(np.unique(yTrain))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cWeights = compute_class_weight(class_weight='balanced',classes=np.unique(yTrain),y=yTrain)\n",
    "sample_weights = np.array([cWeights[0] if y==0 else cWeights[1] for y in yTrain])\n",
    "print(cWeights)\n",
    "xgbModel = xgb.XGBClassifier(scale_pos_weight = cWeights[0]/cWeights[1], enable_categorical=True)\n",
    "# xgbModel = xgb.XGBClassifier(scale_pos_weight = 0.30, enable_categorical=True)\n",
    "# xgbModel.fit(xTrain, yTrain, sample_weight = sample_weights)\n",
    "xgbModel.fit(xTrain, yTrain,sample_weight = sample_weights )\n",
    "y_pred = xgbModel.predict(xTest)\n",
    "print(classification_report(yTest, y_pred))\n",
    "print(\"Accuracy : \",accuracy_score(yTest, y_pred))\n",
    "print(\"roc auc score : \",roc_auc_score(yTest, y_pred,multi_class='ovr', average='macro'))\n",
    "\n",
    "\n",
    "'''\n",
    "o/p :- \n",
    "\n",
    "[0.64285714 2.25      ]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.94      0.93      0.93      7700\n",
    "           1       0.77      0.78      0.77      2200\n",
    "\n",
    "    accuracy                           0.90      9900\n",
    "   macro avg       0.85      0.86      0.85      9900\n",
    "weighted avg       0.90      0.90      0.90      9900\n",
    "\n",
    "Accuracy :  0.8981818181818182\n",
    "roc auc score :  0.8556493506493508\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
